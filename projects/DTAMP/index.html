---
layout: default
title: Diffused Task-Agnostic Milestone Planner
nav_order: 2312
parent: Home
---


<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Diffused Task-Agnostic Milestone Planner">
  <meta name="keywords" content="Planning, Reinforcement Learning, Diffusion Model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Diffused Task-Agnostic Milestone Planner</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-YBLEPL8HN9"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-YBLEPL8HN9');
</script>
 -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Diffused Task-Agnostic Milestone Planner</h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://rllab.snu.ac.kr/people/mineui-hong/">Mineui Hong</a>,</span>
            <span class="author-block">
              <a href="https://rllab.snu.ac.kr/people/minjae-kang/minjae-kang">Minjae Kang</a>,</span>
            <span class="author-block">
              <a href="https://rllab.snu.ac.kr/people/songhwai-oh">Songhwai Oh</a>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Robot Learning Lab, Seoul Natiaonl University,</span>
          </div>
          <div class="is-size-6 publication-venues" style="color: #1ABC9C ">
            <span><b>Presented at NeurIPS 2023</b></span>
          </div>
<!--           <div class="column has-text-centered">
            <div class="publication-links">
              <!-- <span class="link-block">
                <a class="external-link button is-normal is-rounded is-light">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper (Comming Soon) </span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2303.00304"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href='https://github.com/rllab-snu/RNR-Map'
                   class="external-link button is-normal is-rounded is-light">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (comming soon)</span>
                </a>
              </span>
            </div>
          </div> -->
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100% ">
        <source src="./static/videos/overview.mp4"
                type="video/mp4">
      </video>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          We propose a novel type of a map for visual navigation, a renderable neural radiance map (RNR-Map), which is designed to contain the overall visual information of a 3D environment. 
          The RNR-Map has a grid form and consists of latent codes at each pixel. 
          These latent codes are embedded from image observations, and can be converted to the neural radiance field which enables image rendering given a camera pose. 
          The recorded latent codes implicitly contain visual information about the environment, which makes the RNR-Map visually descriptive. 
          This visual information in RNR-Map can be a useful guideline for visual localization and navigation. 
          We develop localization and navigation frameworks that can effectively utilize the RNR-Map. 
          </p>
          <p>
          We evaluate the proposed frameworks on camera tracking, visual localization, and image-goal navigation. 
          Experimental results show that the RNR-Map-based localization framework can find the target location based on a single query image with fast speed and competitive accuracy compared to other baselines. 
          Also, this localization framework is robust to environmental changes, and even finds the most visually similar places when a query image from a different environment is given.  
          The proposed navigation framework outperforms the existing image-goal navigation methods in difficult scenarios, under odometry and actuation noises. 
          The navigation framework shows 65.7% success rate in curved scenarios of the NRNS dataset, which is an improvement of 18.6% over the current state-of-the-art. 
          </p>
          </p>
        </div>
      </div>
    </div>
    <!--/ Overview. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/1SF8_6BsA1c"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
        <!-- <video id="publication-video" controls playsinline height="100%">
          <source src="./rnr_map/videos/RNR_supplementary_video.mp4"
                  type="video/mp4">
        </video> -->
        
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Matting. -->
    <div class="column is-centered">
      <h2 class="title is-3">Mapping</h2>
      <p>
        The proposed method can encode the observation images into latent codes with fast speed of 91.9Hz.
        These latent codes are embedded in the grid map according to its position.
        They can be converted to a neural radiance fields which can render the corresponding region. 
        We provide some examples of building RNR-Map below.
      </p>
      <p>

      </p>
      <div class="container ">
        <img src="./static/images/names.png" />
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-steve">

            <video poster="" id="cantwell" preload='auto' autoplay muted loop playsinline height="100%">
              <source src="./static/videos/mapping/mapping_Cantwell_0.mp4"
                      type="video/mp4">
            </video>
            <video poster="" id="mosquito"  preload='auto' autoplay muted loop playsinline height="100%">
              <source src="./static/videos/mapping/mapping_Mosquito_1.mp4"
                      type="video/mp4">
            </video>
            <video poster="" id="greigsvillew"  preload='auto' autoplay muted loop playsinline height="100%">
              <source src="./static/videos/mapping/mapping_Greigsville_0.mp4"
                      type="video/mp4">
            </video>
          </div>
          <div class="item item-steve">

            <video poster="" id="steve"  preload='auto' autoplay muted loop playsinline height="100%">
              <source src="./static/videos/mapping/mapping_Denmark_0.mp4"
                      type="video/mp4">
            </video>
            <video poster="" id="steve"  preload='auto' autoplay muted loop playsinline height="100%">
              <source src="./static/videos/mapping/mapping_Eudora_0.mp4"
                      type="video/mp4">
            </video>
            <video poster="" id="steve"  preload='auto' autoplay muted loop playsinline height="100%">
              <source src="./static/videos/mapping/mapping_Edgemere_0.mp4"
                      type="video/mp4">
            </video>
          </div>
          <div class="item item-steve">

            <video poster="" id="steve"  preload='auto' autoplay muted loop playsinline height="100%">
              <source src="./static/videos/mapping/mapping_Elmira_0.mp4"
                      type="video/mp4">
            </video>
            <video poster="" id="steve"  preload='auto' autoplay muted loop playsinline height="100%">
              <source src="./static/videos/mapping/mapping_Scioto_0.mp4"
                      type="video/mp4">
            </video>
            <video poster="" id="steve"  preload='auto' autoplay muted loop playsinline height="100%">
              <source src="./static/videos/mapping/mapping_Ribera_4.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>


    </div>

    <!--/ Matting. -->

    <div class="column is-full-width">
      <h2 class="title is-3"> Visual Localization </h2>
      <div class="column is-full-width">
        <h2 class="title is-4"> Visual Localization using RNR-Map</h2>
        <p>
          We can locate places based on an image by directly utilizing the latent codes without rendering images.
          The visual localization process operates with fast speed (56.8Hz) and high accuracy (99% inliers less than 50cm )
        </p>
        <video poster="" id="vl-explain" preload='auto' autoplay muted loop playsinline height="100%">
          <source src="./static/videos/localization/visual_loc_explain.mp4"
                  type="video/mp4">
        </video>

        <div class="container ">
          <h2 class="title is-5"> Visual Localization Example</h2>
          <div id="results-vl" class="carousel results-carousel">
            <div class="item item-steve">
  
              <video poster="" id="vl-1" preload='auto' autoplay muted loop playsinline height="100%">
                <source src="./static/videos/localization/visual_loc_ex1.mp4"
                        type="video/mp4">
              </video>
            </div>
            <div class="item item-steve">
              <video poster="" id="vl-2" preload='auto' autoplay muted loop playsinline height="100%">
                <source src="./static/videos/localization/visual_loc_ex2.mp4"
                        type="video/mp4">
              </video>
            </div>
            <div class="item item-steve">
              <video poster="" id="vl-4" preload='auto' autoplay muted loop playsinline height="100%">
                <source src="./static/videos/localization/visual_loc_ex3.mp4"
                        type="video/mp4">
              </video>
            </div>
          </div>
        </div>

        <video poster="" id="vl-3" preload='auto' autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/localization/visual_loc_ex4.mp4"
                  type="video/mp4">
        </video>

      </div>


      <div class="column is-full-width">
        <h2 class="title is-5"> Visual Localization with Environment Changes </h2>
        <p>
          We observed that visual localization framework with RNR-Map is robust to environment changes. 
        </p>
        <columns>
          <video poster="" id="vl-2" preload='auto' autoplay muted loop playsinline height="100%">
            <source src="./static/videos/localization/visual_loc_ec.mp4"
                    type="video/mp4">
          </video>
          <video poster="" id="vl-2" preload='auto' autoplay muted loop playsinline height="100%">
            <source src="./static/videos/localization/visual_loc_ec2.mp4"
                    type="video/mp4">
          </video>
        </columns>


      </div>

      <div class="column is-full-width">
        <h2 class="title is-4"> Camera Tracking using RNR-Map </h2>
        <p>
          The renderable property of RNR-Map also enables fine-level pose prediction. 
        </p>
      </div>
        <div class="container ">
          <div id="results-vl" class="carousel results-carousel">
            <div class="item item-steve">
  
              <video poster="" id="vl-ct" preload='auto' autoplay muted loop playsinline height="100%">
                <source src="./static/videos/localization/camera_tracking.mp4"
                        type="video/mp4">
              </video>
            </div>
            <div class="item item-steve">
              <video poster="" id="vl-ct2" preload='auto' autoplay muted loop playsinline height="100%">
                <source src="./static/videos/localization/camera_tracking2.mp4"
                        type="video/mp4">
              </video>
            </div>
          </div>
        </div>

    </div>


    <div class="column is-full-width">
      <h2 class="title is-3"> Visual Navigation </h2>
      <div class="column is-full-width">
        <h2 class="title is-4"> Image Goal Navigation </h2>
        <p>
          The visual information in RNR-Map is useful for exploring an environment when finding an image query. 
        </p>
        <video poster="" id="img-navi" preload='auto' autoplay muted loop playsinline height="100%">
          <source src="./static/videos/navigation/image_goal_navi.mp4"
                  type="video/mp4">
        </video>


        <div class="column ">
        <h2 class="title is-5"> Agent Behavior</h2>
        <div id="results-vl" class="carousel results-carousel">
          <div class="item item-steve">
  
            <video poster="" id="vl-ct" preload='auto' autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/navigation/navi_example1.mp4"
                      type="video/mp4">
            </video>
          </div>
          <div class="item item-steve">

            <video poster="" id="vl-ct" preload='auto' autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/navigation/navi_example2.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
        <span> </span>
        <div class="column ">
          <h2 class="title is-5"> Other Navigation Examples </h2>
          <div id="results-vl" class="carousel results-carousel">
            <div class="item item-steve">
  
              <video poster="" id="vl-ct" preload='auto' autoplay muted loop playsinline height="100%">
                <source src="./static/videos/navigation/navi_example3.mp4"
                        type="video/mp4">
              </video>
            </div>
            <div class="item item-steve">
  
              <video poster="" id="vl-ct" preload='auto' autoplay muted loop playsinline height="100%">
                <source src="./static/videos/navigation/navi_example4.mp4"
                        type="video/mp4">
              </video>
            </div>
            <div class="item item-steve">
  
              <video poster="" id="vl-ct" preload='auto' autoplay muted loop playsinline height="100%">
                <source src="./static/videos/navigation/navi_example5.mp4"
                        type="video/mp4">
              </video>
            </div>
            
          </div>
        </div>
      </div>
    </div>

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@InProceedings{Kwon_2023_CVPR,
     author    = {Kwon, Obin and Park, Jeongho and Oh, Songhwai},
     title     = {Renderable Neural Radiance Map for Visual Navigation},
     booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
     month     = {June},
     year      = {2023},
     pages     = {9099-9108}
 }</code></pre>
  </div>
</section>
 -->

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/2023_CVPR_arXiv.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/obin-hero" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
            This webpage template is from <a rel="Nerfies" href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
